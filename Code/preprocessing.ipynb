{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg #another version of opencv display image. I think it's just rendering things that have a height, width, and color dimensionality to them\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #using because this is a cnn and we want it to handle images in a fast manner\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Special\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/phys_chem_reddit_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Wrangling and Preprocessing\n",
    "- using nltk and spacy\n",
    "\n",
    "Outline:\n",
    "- Start by using CountVectorizer to convert text data into a structured, numeric `X` dataframe\n",
    "- Removing accented characters\n",
    "- Expanding contractions (doesn't work because of Java error)\n",
    "- Removing special characters\n",
    "- Tokenizing\n",
    "- Exploring stemming\n",
    "- Exploring lemmatizing\n",
    "- Removing stop words (adding a few that aren't there)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract features from unstructured text by fitting and transforming with `CountVectorizer` and `TfidfVectorizer`.\n",
    "- Describe how CountVectorizers and TF-IDFVectorizers work.\n",
    "- Understand `stop_words`, `max_features`, `min_df`, `max_df`, and `ngram_range`.\n",
    "- Implement `CountVectorizer` and `TfidfVectorizer` in a spam classification model.\n",
    "- Use `GridSearchCV` and `Pipeline` with `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@!\", remove_digits=True)\n",
    "# from Dipanjan (DJ) Sarkar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['selftext_nochar'] = data.apply(lambda row: remove_special_characters(row['selftext'], remove_digits=True), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_nochar'] = data.apply(lambda row: remove_special_characters(row['title'], remove_digits=True), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Choice of GPU for running MD simulation (NAMD and GROMACS)'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Choice of GPU for running MD simulation NAMD and GROMACS'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title_nochar'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "remove_accented_chars('Sómě Áccěntěd těxt')\n",
    "# from Dipanjan (DJ) Sarkar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['selftext_noacccent'] = data.apply(lambda row: remove_special_characters(row['selftext_nochar'], remove_digits=True), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_noacccent'] = data.apply(lambda row: remove_special_characters(row['title_nochar'], remove_digits=True), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Choice of GPU for running MD simulation (NAMD and GROMACS)'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Choice of GPU for running MD simulation NAMD and GROMACS'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title_noacccent'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expanding contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://pypi.org/project/pycontractions/\n",
    "#!pip install pycontractions\n",
    "#get error: \"to use the 'java' command-line tool you need to install a JDK\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put them all together, create new dataframe with cleaned columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['subreddit', 'selftext_noacccent', 'title_noacccent']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physics</td>\n",
       "      <td>I am planning to set up a home PC with AMD Ryz...</td>\n",
       "      <td>Choice of GPU for running MD simulation NAMD a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Physics</td>\n",
       "      <td>Ok So I have a bit of a bizarre question I bel...</td>\n",
       "      <td>Balance Bird vs Spin top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Physics</td>\n",
       "      <td>Would this account for spin  Observations in q...</td>\n",
       "      <td>Do electrons have convective cores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physics</td>\n",
       "      <td>According to the [Bekenstein bound]httpsenwiki...</td>\n",
       "      <td>Is quantum computing dangerous or impposible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physics</td>\n",
       "      <td>So I understand conceptually the Big Rip but w...</td>\n",
       "      <td>On The Big Rip and The Mighty Quark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                           selftext  \\\n",
       "0   Physics  I am planning to set up a home PC with AMD Ryz...   \n",
       "1   Physics  Ok So I have a bit of a bizarre question I bel...   \n",
       "2   Physics  Would this account for spin  Observations in q...   \n",
       "3   Physics  According to the [Bekenstein bound]httpsenwiki...   \n",
       "4   Physics  So I understand conceptually the Big Rip but w...   \n",
       "\n",
       "                                               title  \n",
       "0  Choice of GPU for running MD simulation NAMD a...  \n",
       "1                           Balance Bird vs Spin top  \n",
       "2                 Do electrons have convective cores  \n",
       "3       Is quantum computing dangerous or impposible  \n",
       "4                On The Big Rip and The Mighty Quark  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['subreddit', 'selftext', 'title']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext_tokenized'] = df.apply(lambda row: tokenizer.tokenize(row['selftext']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_tokenized'] = df.apply(lambda row: tokenizer.tokenize(row['title']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physics</td>\n",
       "      <td>I am planning to set up a home PC with AMD Ryz...</td>\n",
       "      <td>Choice of GPU for running MD simulation NAMD a...</td>\n",
       "      <td>[I, am, planning, to, set, up, a, home, PC, wi...</td>\n",
       "      <td>[Choice, of, GPU, for, running, MD, simulation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Physics</td>\n",
       "      <td>Ok So I have a bit of a bizarre question I bel...</td>\n",
       "      <td>Balance Bird vs Spin top</td>\n",
       "      <td>[Ok, So, I, have, a, bit, of, a, bizarre, ques...</td>\n",
       "      <td>[Balance, Bird, vs, Spin, top]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Physics</td>\n",
       "      <td>Would this account for spin  Observations in q...</td>\n",
       "      <td>Do electrons have convective cores</td>\n",
       "      <td>[Would, this, account, for, spin, Observations...</td>\n",
       "      <td>[Do, electrons, have, convective, cores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physics</td>\n",
       "      <td>According to the [Bekenstein bound]httpsenwiki...</td>\n",
       "      <td>Is quantum computing dangerous or impposible</td>\n",
       "      <td>[According, to, the, Bekenstein, bound, httpse...</td>\n",
       "      <td>[Is, quantum, computing, dangerous, or, imppos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physics</td>\n",
       "      <td>So I understand conceptually the Big Rip but w...</td>\n",
       "      <td>On The Big Rip and The Mighty Quark</td>\n",
       "      <td>[So, I, understand, conceptually, the, Big, Ri...</td>\n",
       "      <td>[On, The, Big, Rip, and, The, Mighty, Quark]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                           selftext  \\\n",
       "0   Physics  I am planning to set up a home PC with AMD Ryz...   \n",
       "1   Physics  Ok So I have a bit of a bizarre question I bel...   \n",
       "2   Physics  Would this account for spin  Observations in q...   \n",
       "3   Physics  According to the [Bekenstein bound]httpsenwiki...   \n",
       "4   Physics  So I understand conceptually the Big Rip but w...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Choice of GPU for running MD simulation NAMD a...   \n",
       "1                           Balance Bird vs Spin top   \n",
       "2                 Do electrons have convective cores   \n",
       "3       Is quantum computing dangerous or impposible   \n",
       "4                On The Big Rip and The Mighty Quark   \n",
       "\n",
       "                                  selftext_tokenized  \\\n",
       "0  [I, am, planning, to, set, up, a, home, PC, wi...   \n",
       "1  [Ok, So, I, have, a, bit, of, a, bizarre, ques...   \n",
       "2  [Would, this, account, for, spin, Observations...   \n",
       "3  [According, to, the, Bekenstein, bound, httpse...   \n",
       "4  [So, I, understand, conceptually, the, Big, Ri...   \n",
       "\n",
       "                                     title_tokenized  \n",
       "0  [Choice, of, GPU, for, running, MD, simulation...  \n",
       "1                     [Balance, Bird, vs, Spin, top]  \n",
       "2           [Do, electrons, have, convective, cores]  \n",
       "3  [Is, quantum, computing, dangerous, or, imppos...  \n",
       "4       [On, The, Big, Rip, and, The, Mighty, Quark]  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lemmatizer. \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Instantiate lemmatizer. \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define funciton to lemmatize words in string\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in tokenizer.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext_lemmatized'] = df.apply(lambda row: lemmatize_text(row['selftext']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_lemmatized'] = df.apply(lambda row: lemmatize_text(row['title']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stopwords.\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sophiascarano/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define funciton to remove stop words in string\n",
    "def no_stop_text(text):\n",
    "    text = [token for token in text if token not in stopwords.words('english')]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext_nostop'] = df.apply(lambda row: no_stop_text(row['selftext_lemmatized']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_nostop'] = df.apply(lambda row: no_stop_text(row['title_lemmatized']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "- a bit of a crude way to lemmatize. Might prove to be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stemmer.\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Instantiate object of class PorterStemmer.\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define funciton to stem words in string\n",
    "def stem_text(text):\n",
    "    return [p_stemmer.stem(w) for w in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['selftext_stemmed'] = df.apply(lambda row: stem_text(row['selftext_nostop']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_stemmed'] = df.apply(lambda row: stem_text(row['title_nostop']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>selftext_lemmatized</th>\n",
       "      <th>title_lemmatized</th>\n",
       "      <th>selftext_stemmed</th>\n",
       "      <th>title_stemmed</th>\n",
       "      <th>title_nostop</th>\n",
       "      <th>selftext_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physics</td>\n",
       "      <td>I am planning to set up a home PC with AMD Ryz...</td>\n",
       "      <td>Choice of GPU for running MD simulation NAMD a...</td>\n",
       "      <td>[I, am, planning, to, set, up, a, home, PC, wi...</td>\n",
       "      <td>[Choice, of, GPU, for, running, MD, simulation...</td>\n",
       "      <td>[I, am, planning, to, set, up, a, home, PC, wi...</td>\n",
       "      <td>[Choice, of, GPU, for, running, MD, simulation...</td>\n",
       "      <td>[I, plan, set, home, PC, amd, ryzen, X, proces...</td>\n",
       "      <td>[choic, gpu, run, MD, simul, namd, gromac]</td>\n",
       "      <td>[Choice, GPU, running, MD, simulation, NAMD, G...</td>\n",
       "      <td>[I, planning, set, home, PC, AMD, Ryzen, X, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Physics</td>\n",
       "      <td>Ok So I have a bit of a bizarre question I bel...</td>\n",
       "      <td>Balance Bird vs Spin top</td>\n",
       "      <td>[Ok, So, I, have, a, bit, of, a, bizarre, ques...</td>\n",
       "      <td>[Balance, Bird, vs, Spin, top]</td>\n",
       "      <td>[Ok, So, I, have, a, bit, of, a, bizarre, ques...</td>\n",
       "      <td>[Balance, Bird, v, Spin, top]</td>\n",
       "      <td>[Ok, So, I, bit, bizarr, question, I, believ, ...</td>\n",
       "      <td>[balanc, bird, v, spin, top]</td>\n",
       "      <td>[Balance, Bird, v, Spin, top]</td>\n",
       "      <td>[Ok, So, I, bit, bizarre, question, I, believe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Physics</td>\n",
       "      <td>Would this account for spin  Observations in q...</td>\n",
       "      <td>Do electrons have convective cores</td>\n",
       "      <td>[Would, this, account, for, spin, Observations...</td>\n",
       "      <td>[Do, electrons, have, convective, cores]</td>\n",
       "      <td>[Would, this, account, for, spin, Observations...</td>\n",
       "      <td>[Do, electron, have, convective, core]</td>\n",
       "      <td>[would, account, spin, observ, quantum, mechan...</td>\n",
       "      <td>[Do, electron, convect, core]</td>\n",
       "      <td>[Do, electron, convective, core]</td>\n",
       "      <td>[Would, account, spin, Observations, quantum, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physics</td>\n",
       "      <td>According to the [Bekenstein bound]httpsenwiki...</td>\n",
       "      <td>Is quantum computing dangerous or impposible</td>\n",
       "      <td>[According, to, the, Bekenstein, bound, httpse...</td>\n",
       "      <td>[Is, quantum, computing, dangerous, or, imppos...</td>\n",
       "      <td>[According, to, the, Bekenstein, bound, httpse...</td>\n",
       "      <td>[Is, quantum, computing, dangerous, or, imppos...</td>\n",
       "      <td>[accord, bekenstein, bound, httpsenwikipediaor...</td>\n",
       "      <td>[Is, quantum, comput, danger, imppos]</td>\n",
       "      <td>[Is, quantum, computing, dangerous, impposible]</td>\n",
       "      <td>[According, Bekenstein, bound, httpsenwikipedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physics</td>\n",
       "      <td>So I understand conceptually the Big Rip but w...</td>\n",
       "      <td>On The Big Rip and The Mighty Quark</td>\n",
       "      <td>[So, I, understand, conceptually, the, Big, Ri...</td>\n",
       "      <td>[On, The, Big, Rip, and, The, Mighty, Quark]</td>\n",
       "      <td>[So, I, understand, conceptually, the, Big, Ri...</td>\n",
       "      <td>[On, The, Big, Rip, and, The, Mighty, Quark]</td>\n",
       "      <td>[So, I, understand, conceptu, big, rip, I, can...</td>\n",
       "      <td>[On, the, big, rip, the, mighti, quark]</td>\n",
       "      <td>[On, The, Big, Rip, The, Mighty, Quark]</td>\n",
       "      <td>[So, I, understand, conceptually, Big, Rip, I,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                           selftext  \\\n",
       "0   Physics  I am planning to set up a home PC with AMD Ryz...   \n",
       "1   Physics  Ok So I have a bit of a bizarre question I bel...   \n",
       "2   Physics  Would this account for spin  Observations in q...   \n",
       "3   Physics  According to the [Bekenstein bound]httpsenwiki...   \n",
       "4   Physics  So I understand conceptually the Big Rip but w...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Choice of GPU for running MD simulation NAMD a...   \n",
       "1                           Balance Bird vs Spin top   \n",
       "2                 Do electrons have convective cores   \n",
       "3       Is quantum computing dangerous or impposible   \n",
       "4                On The Big Rip and The Mighty Quark   \n",
       "\n",
       "                                  selftext_tokenized  \\\n",
       "0  [I, am, planning, to, set, up, a, home, PC, wi...   \n",
       "1  [Ok, So, I, have, a, bit, of, a, bizarre, ques...   \n",
       "2  [Would, this, account, for, spin, Observations...   \n",
       "3  [According, to, the, Bekenstein, bound, httpse...   \n",
       "4  [So, I, understand, conceptually, the, Big, Ri...   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0  [Choice, of, GPU, for, running, MD, simulation...   \n",
       "1                     [Balance, Bird, vs, Spin, top]   \n",
       "2           [Do, electrons, have, convective, cores]   \n",
       "3  [Is, quantum, computing, dangerous, or, imppos...   \n",
       "4       [On, The, Big, Rip, and, The, Mighty, Quark]   \n",
       "\n",
       "                                 selftext_lemmatized  \\\n",
       "0  [I, am, planning, to, set, up, a, home, PC, wi...   \n",
       "1  [Ok, So, I, have, a, bit, of, a, bizarre, ques...   \n",
       "2  [Would, this, account, for, spin, Observations...   \n",
       "3  [According, to, the, Bekenstein, bound, httpse...   \n",
       "4  [So, I, understand, conceptually, the, Big, Ri...   \n",
       "\n",
       "                                    title_lemmatized  \\\n",
       "0  [Choice, of, GPU, for, running, MD, simulation...   \n",
       "1                      [Balance, Bird, v, Spin, top]   \n",
       "2             [Do, electron, have, convective, core]   \n",
       "3  [Is, quantum, computing, dangerous, or, imppos...   \n",
       "4       [On, The, Big, Rip, and, The, Mighty, Quark]   \n",
       "\n",
       "                                    selftext_stemmed  \\\n",
       "0  [I, plan, set, home, PC, amd, ryzen, X, proces...   \n",
       "1  [Ok, So, I, bit, bizarr, question, I, believ, ...   \n",
       "2  [would, account, spin, observ, quantum, mechan...   \n",
       "3  [accord, bekenstein, bound, httpsenwikipediaor...   \n",
       "4  [So, I, understand, conceptu, big, rip, I, can...   \n",
       "\n",
       "                                title_stemmed  \\\n",
       "0  [choic, gpu, run, MD, simul, namd, gromac]   \n",
       "1                [balanc, bird, v, spin, top]   \n",
       "2               [Do, electron, convect, core]   \n",
       "3       [Is, quantum, comput, danger, imppos]   \n",
       "4     [On, the, big, rip, the, mighti, quark]   \n",
       "\n",
       "                                        title_nostop  \\\n",
       "0  [Choice, GPU, running, MD, simulation, NAMD, G...   \n",
       "1                      [Balance, Bird, v, Spin, top]   \n",
       "2                   [Do, electron, convective, core]   \n",
       "3    [Is, quantum, computing, dangerous, impposible]   \n",
       "4            [On, The, Big, Rip, The, Mighty, Quark]   \n",
       "\n",
       "                                     selftext_nostop  \n",
       "0  [I, planning, set, home, PC, AMD, Ryzen, X, pr...  \n",
       "1  [Ok, So, I, bit, bizarre, question, I, believe...  \n",
       "2  [Would, account, spin, Observations, quantum, ...  \n",
       "3  [According, Bekenstein, bound, httpsenwikipedi...  \n",
       "4  [So, I, understand, conceptually, Big, Rip, I,...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping values: 'subreddit' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = df['subreddit'].map({'Physics': 1, 'chemistry': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext_tokenized</th>\n",
       "      <th>title_tokenized</th>\n",
       "      <th>selftext_lemmatized</th>\n",
       "      <th>title_lemmatized</th>\n",
       "      <th>selftext_stemmed</th>\n",
       "      <th>title_stemmed</th>\n",
       "      <th>title_nostop</th>\n",
       "      <th>selftext_nostop</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am planning to set up a home PC with AMD Ryz...</td>\n",
       "      <td>Choice of GPU for running MD simulation NAMD a...</td>\n",
       "      <td>[I, am, planning, to, set, up, a, home, PC, wi...</td>\n",
       "      <td>[Choice, of, GPU, for, running, MD, simulation...</td>\n",
       "      <td>[I, am, planning, to, set, up, a, home, PC, wi...</td>\n",
       "      <td>[Choice, of, GPU, for, running, MD, simulation...</td>\n",
       "      <td>[I, plan, set, home, PC, amd, ryzen, X, proces...</td>\n",
       "      <td>[choic, gpu, run, MD, simul, namd, gromac]</td>\n",
       "      <td>[Choice, GPU, running, MD, simulation, NAMD, G...</td>\n",
       "      <td>[I, planning, set, home, PC, AMD, Ryzen, X, pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                           selftext  \\\n",
       "0          1  I am planning to set up a home PC with AMD Ryz...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Choice of GPU for running MD simulation NAMD a...   \n",
       "\n",
       "                                  selftext_tokenized  \\\n",
       "0  [I, am, planning, to, set, up, a, home, PC, wi...   \n",
       "\n",
       "                                     title_tokenized  \\\n",
       "0  [Choice, of, GPU, for, running, MD, simulation...   \n",
       "\n",
       "                                 selftext_lemmatized  \\\n",
       "0  [I, am, planning, to, set, up, a, home, PC, wi...   \n",
       "\n",
       "                                    title_lemmatized  \\\n",
       "0  [Choice, of, GPU, for, running, MD, simulation...   \n",
       "\n",
       "                                    selftext_stemmed  \\\n",
       "0  [I, plan, set, home, PC, amd, ryzen, X, proces...   \n",
       "\n",
       "                                title_stemmed  \\\n",
       "0  [choic, gpu, run, MD, simul, namd, gromac]   \n",
       "\n",
       "                                        title_nostop  \\\n",
       "0  [Choice, GPU, running, MD, simulation, NAMD, G...   \n",
       "\n",
       "                                     selftext_nostop  test  \n",
       "0  [I, planning, set, home, PC, AMD, Ryzen, X, pr...     1  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataframes for ease of use\n",
    "- in both dataframes, stop words, accents, and numbers were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I planning set home PC AMD Ryzen X processor G...</td>\n",
       "      <td>Choice GPU running MD simulation NAMD GROMACS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok So I bit bizarre question I believe I under...</td>\n",
       "      <td>Balance Bird v Spin top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Would account spin Observations quantum mechan...</td>\n",
       "      <td>Do electron convective core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>According Bekenstein bound httpsenwikipediaorg...</td>\n",
       "      <td>Is quantum computing dangerous impposible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>So I understand conceptually Big Rip I cant ge...</td>\n",
       "      <td>On The Big Rip The Mighty Quark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                           selftext  \\\n",
       "0          1  I planning set home PC AMD Ryzen X processor G...   \n",
       "1          1  Ok So I bit bizarre question I believe I under...   \n",
       "2          1  Would account spin Observations quantum mechan...   \n",
       "3          1  According Bekenstein bound httpsenwikipediaorg...   \n",
       "4          1  So I understand conceptually Big Rip I cant ge...   \n",
       "\n",
       "                                           title  \n",
       "0  Choice GPU running MD simulation NAMD GROMACS  \n",
       "1                        Balance Bird v Spin top  \n",
       "2                    Do electron convective core  \n",
       "3      Is quantum computing dangerous impposible  \n",
       "4                On The Big Rip The Mighty Quark  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nostop_lemmatized = df[['subreddit', 'selftext_nostop', 'title_nostop']].copy()\n",
    "df_nostop_lemmatized.columns = ['subreddit', 'selftext', 'title']\n",
    "\n",
    "#convert from list to string for columns\n",
    "df_nostop_lemmatized['selftext'] = df_nostop_lemmatized['selftext'].apply(' '.join)\n",
    "df_nostop_lemmatized['title'] = df_nostop_lemmatized['title'].apply(' '.join)\n",
    "\n",
    "df_nostop_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I plan set home PC amd ryzen X processor GB ra...</td>\n",
       "      <td>choic gpu run MD simul namd gromac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok So I bit bizarr question I believ I underst...</td>\n",
       "      <td>balanc bird v spin top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>would account spin observ quantum mechan gener...</td>\n",
       "      <td>Do electron convect core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>accord bekenstein bound httpsenwikipediaorgwik...</td>\n",
       "      <td>Is quantum comput danger imppos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>So I understand conceptu big rip I cant get he...</td>\n",
       "      <td>On the big rip the mighti quark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                           selftext  \\\n",
       "0          1  I plan set home PC amd ryzen X processor GB ra...   \n",
       "1          1  Ok So I bit bizarr question I believ I underst...   \n",
       "2          1  would account spin observ quantum mechan gener...   \n",
       "3          1  accord bekenstein bound httpsenwikipediaorgwik...   \n",
       "4          1  So I understand conceptu big rip I cant get he...   \n",
       "\n",
       "                                title  \n",
       "0  choic gpu run MD simul namd gromac  \n",
       "1              balanc bird v spin top  \n",
       "2            Do electron convect core  \n",
       "3     Is quantum comput danger imppos  \n",
       "4     On the big rip the mighti quark  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nostop_stemmed = df[['subreddit', 'selftext_stemmed', 'title_stemmed']].copy()\n",
    "df_nostop_stemmed.columns = ['subreddit', 'selftext', 'title']\n",
    "\n",
    "#convert from list to string for columns\n",
    "df_nostop_stemmed['selftext'] = df_nostop_stemmed['selftext'].apply(' '.join)\n",
    "df_nostop_stemmed['title'] = df_nostop_stemmed['title'].apply(' '.join)\n",
    "\n",
    "df_nostop_stemmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### covert these to csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nostop_lemmatized.to_csv(r'./data/lemmatized_nostop_data.csv', index = False)\n",
    "df_nostop_stemmed.to_csv(r'./data/stemmed_nostop_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CountVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using lemmatized data, only selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_nostop_lemmatized['selftext']\n",
    "y = df_nostop_lemmatized['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a CountVectorizer.\n",
    "cvec = CountVectorizer(stop_words = 'english', ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(ngram_range=(1, 2), stop_words='english')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the vectorizer on our corpus.\n",
    "cvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the corpus.\n",
    "X_train = cvec.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>____</th>\n",
       "      <th>____ ____</th>\n",
       "      <th>____ froze</th>\n",
       "      <th>________</th>\n",
       "      <th>________ gt</th>\n",
       "      <th>__main__</th>\n",
       "      <th>__main__ main</th>\n",
       "      <th>__name__</th>\n",
       "      <th>__name__ __main__</th>\n",
       "      <th>_a</th>\n",
       "      <th>...</th>\n",
       "      <th>zumdahl</th>\n",
       "      <th>zumdahl content</th>\n",
       "      <th>zwiebachs</th>\n",
       "      <th>zwiebachs course</th>\n",
       "      <th>zwitterion</th>\n",
       "      <th>zwitterion ha</th>\n",
       "      <th>zygote</th>\n",
       "      <th>zygote dividing</th>\n",
       "      <th>zzzzz</th>\n",
       "      <th>zzzzz programm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2576 rows × 98036 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ____  ____ ____  ____ froze  ________  ________ gt  __main__  \\\n",
       "0        0          0           0         0            0         0   \n",
       "1        0          0           0         0            0         0   \n",
       "2        0          0           0         0            0         0   \n",
       "3        0          0           0         0            0         0   \n",
       "4        0          0           0         0            0         0   \n",
       "...    ...        ...         ...       ...          ...       ...   \n",
       "2571     0          0           0         0            0         0   \n",
       "2572     0          0           0         0            0         0   \n",
       "2573     0          0           0         0            0         0   \n",
       "2574     0          0           0         0            0         0   \n",
       "2575     0          0           0         0            0         0   \n",
       "\n",
       "      __main__ main  __name__  __name__ __main__  _a  ...  zumdahl  \\\n",
       "0                 0         0                  0   0  ...        0   \n",
       "1                 0         0                  0   0  ...        0   \n",
       "2                 0         0                  0   0  ...        0   \n",
       "3                 0         0                  0   0  ...        0   \n",
       "4                 0         0                  0   0  ...        0   \n",
       "...             ...       ...                ...  ..  ...      ...   \n",
       "2571              0         0                  0   0  ...        0   \n",
       "2572              0         0                  0   0  ...        0   \n",
       "2573              0         0                  0   0  ...        0   \n",
       "2574              0         0                  0   0  ...        0   \n",
       "2575              0         0                  0   0  ...        0   \n",
       "\n",
       "      zumdahl content  zwiebachs  zwiebachs course  zwitterion  zwitterion ha  \\\n",
       "0                   0          0                 0           0              0   \n",
       "1                   0          0                 0           0              0   \n",
       "2                   0          0                 0           0              0   \n",
       "3                   0          0                 0           0              0   \n",
       "4                   0          0                 0           0              0   \n",
       "...               ...        ...               ...         ...            ...   \n",
       "2571                0          0                 0           0              0   \n",
       "2572                0          0                 0           0              0   \n",
       "2573                0          0                 0           0              0   \n",
       "2574                0          0                 0           0              0   \n",
       "2575                0          0                 0           0              0   \n",
       "\n",
       "      zygote  zygote dividing  zzzzz  zzzzz programm  \n",
       "0          0                0      0               0  \n",
       "1          0                0      0               0  \n",
       "2          0                0      0               0  \n",
       "3          0                0      0               0  \n",
       "4          0                0      0               0  \n",
       "...      ...              ...    ...             ...  \n",
       "2571       0                0      0               0  \n",
       "2572       0                0      0               0  \n",
       "2573       0                0      0               0  \n",
       "2574       0                0      0               0  \n",
       "2575       0                0      0               0  \n",
       "\n",
       "[2576 rows x 98036 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X_train into a DataFrame.\n",
    "# We will not actually use this for modeling,\n",
    "# this is just to visualize what is happening\n",
    "X_train_df = pd.DataFrame(X_train.toarray(),\n",
    "                          columns=cvec.get_feature_names())\n",
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'countvectorizer__max_features': [2000, 3000, 4000, 5000],\n",
    "    'countvectorizer__min_df': [2, 3],\n",
    "    'countvectorizer__max_df': [.9, .95],\n",
    "    'countvectorizer__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "clf = LogisticRegression()\n",
    "cvect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(cvect, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  pipe_params, # what parameters values are we searching?\n",
    "                  cv = 5, # 5-fold cross-validation.\n",
    "                n_jobs = -1\n",
    "                 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-6ccff0a981dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit GridSearch to training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
